{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset(\"wikitext\", name=\"wikitext-2-raw-v1\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yn = pd.read_csv(\"C:/Users/USER/삼성화재/git_share/hyper-personalized_car_accident_prediction/Dataset/고객별 사고 유무 기본 데이터.csv\", encoding = \"UTF-8\", engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "연령대           float64\n",
       "성별            float64\n",
       "국산차량여부        float64\n",
       "직전3년간사고건수      object\n",
       "차량경과년수         object\n",
       "차종             object\n",
       "운전자한정특별약관      object\n",
       "가입경력코드        float64\n",
       "차량가입금액         object\n",
       "영상기록장치특약가입     object\n",
       "마일리지약정거리       object\n",
       "유효대수            int64\n",
       "사고유무            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_decimal_and_convert_to_str(value):\n",
    "    if pd.isnull(value):\n",
    "        return 'nan'\n",
    "    if isinstance(value, float):\n",
    "        value = int(value) if value.is_integer() else value\n",
    "    return str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yn['processed'] = df_yn.apply(lambda row: '/'.join(row.apply(remove_decimal_and_convert_to_str)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yn['processed'] = df_yn.apply(lambda row: '/'.join(row.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0/1/nan/N/신차/기타/기명피보험자1인한정/8/미가입/미가입/15000K/1/0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yn[\"processed\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_yn['processed'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [int(sentence.split('/')[-1]) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.3.0-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.0-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.3.0-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\program files\\python310\\lib\\site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\program files\\python310\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\program files\\python310\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\program files\\python310\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp310-cp310-win_amd64.whl (159.8 MB)\n",
      "   ---------------------------------------- 0.0/159.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/159.8 MB 10.9 MB/s eta 0:00:15\n",
      "   ---------------------------------------- 0.7/159.8 MB 8.7 MB/s eta 0:00:19\n",
      "   ---------------------------------------- 1.0/159.8 MB 7.8 MB/s eta 0:00:21\n",
      "   ---------------------------------------- 1.3/159.8 MB 7.3 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 1.6/159.8 MB 7.3 MB/s eta 0:00:22\n",
      "    --------------------------------------- 2.1/159.8 MB 7.8 MB/s eta 0:00:21\n",
      "    --------------------------------------- 2.6/159.8 MB 8.2 MB/s eta 0:00:20\n",
      "    --------------------------------------- 3.1/159.8 MB 9.0 MB/s eta 0:00:18\n",
      "    --------------------------------------- 3.4/159.8 MB 8.4 MB/s eta 0:00:19\n",
      "    --------------------------------------- 3.9/159.8 MB 8.6 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 4.5/159.8 MB 9.0 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 5.1/159.8 MB 9.3 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 5.6/159.8 MB 9.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 6.1/159.8 MB 9.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 6.5/159.8 MB 9.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.0/159.8 MB 9.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.5/159.8 MB 9.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.9/159.8 MB 9.6 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.9/159.8 MB 9.2 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 8.4/159.8 MB 9.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 8.7/159.8 MB 9.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 9.2/159.8 MB 9.2 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 9.6/159.8 MB 9.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 10.2/159.8 MB 9.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 10.6/159.8 MB 9.5 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 11.2/159.8 MB 9.8 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 11.6/159.8 MB 9.9 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 12.1/159.8 MB 10.1 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 12.6/159.8 MB 10.1 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 13.1/159.8 MB 9.9 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 13.6/159.8 MB 10.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 14.1/159.8 MB 10.1 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 14.7/159.8 MB 10.1 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 15.2/159.8 MB 10.1 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 15.8/159.8 MB 10.1 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 16.3/159.8 MB 10.2 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 16.8/159.8 MB 10.2 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 17.3/159.8 MB 10.2 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 17.8/159.8 MB 10.2 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 18.3/159.8 MB 10.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 18.9/159.8 MB 11.1 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 19.5/159.8 MB 11.3 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 20.0/159.8 MB 11.5 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 20.5/159.8 MB 11.3 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 21.0/159.8 MB 11.3 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 21.4/159.8 MB 11.3 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 21.4/159.8 MB 11.3 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 22.6/159.8 MB 11.5 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 23.1/159.8 MB 11.7 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 23.5/159.8 MB 11.7 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 24.1/159.8 MB 11.7 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 24.6/159.8 MB 11.5 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 25.0/159.8 MB 11.5 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 25.5/159.8 MB 11.3 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 26.0/159.8 MB 11.3 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 26.5/159.8 MB 11.1 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 27.0/159.8 MB 11.1 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 27.5/159.8 MB 11.5 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 28.0/159.8 MB 11.3 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 28.4/159.8 MB 11.1 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 29.0/159.8 MB 11.1 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 29.6/159.8 MB 11.3 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 30.1/159.8 MB 11.1 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 30.6/159.8 MB 11.1 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 31.0/159.8 MB 10.9 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 31.5/159.8 MB 10.9 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 32.0/159.8 MB 12.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 32.4/159.8 MB 11.3 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 32.9/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 33.2/159.8 MB 10.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 33.7/159.8 MB 10.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 34.2/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 34.7/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 35.2/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 35.7/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 36.2/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 36.7/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 37.3/159.8 MB 10.9 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 37.8/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 38.3/159.8 MB 10.9 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 38.9/159.8 MB 10.9 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 39.4/159.8 MB 10.9 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 39.9/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 40.2/159.8 MB 10.4 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 40.7/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 41.2/159.8 MB 10.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 41.8/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 42.3/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 42.8/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 43.3/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 43.8/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 44.2/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 44.6/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 45.1/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 45.6/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 46.2/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 46.7/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 47.1/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 47.7/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 48.2/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 48.7/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 49.3/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 49.7/159.8 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 50.4/159.8 MB 11.3 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 50.8/159.8 MB 11.3 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 51.2/159.8 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 51.7/159.8 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 52.2/159.8 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 52.8/159.8 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 53.3/159.8 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 53.9/159.8 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 54.5/159.8 MB 11.3 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 55.0/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 55.5/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 56.1/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 56.5/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 57.2/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 57.7/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 58.2/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 58.6/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 59.0/159.8 MB 11.3 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 59.5/159.8 MB 11.3 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 60.0/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 60.5/159.8 MB 11.3 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 61.1/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 61.7/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 62.2/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 62.6/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 63.1/159.8 MB 11.3 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 63.7/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 64.3/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 64.8/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 65.4/159.8 MB 11.7 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 65.8/159.8 MB 11.5 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.3/159.8 MB 11.3 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.6/159.8 MB 11.3 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 67.1/159.8 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 67.7/159.8 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 68.2/159.8 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 68.8/159.8 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 69.3/159.8 MB 11.3 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 69.9/159.8 MB 11.7 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 70.4/159.8 MB 11.5 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 70.7/159.8 MB 11.5 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 71.2/159.8 MB 11.3 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 71.7/159.8 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 72.1/159.8 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 72.5/159.8 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 73.0/159.8 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 73.5/159.8 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 73.8/159.8 MB 10.7 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 74.4/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 74.7/159.8 MB 10.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 75.3/159.8 MB 10.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 75.8/159.8 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 76.2/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 76.7/159.8 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 77.3/159.8 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 77.8/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 78.4/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 78.9/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 79.3/159.8 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 79.8/159.8 MB 10.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 80.2/159.8 MB 10.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 80.7/159.8 MB 10.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 81.2/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 81.8/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 82.3/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 82.7/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 83.1/159.8 MB 10.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 83.6/159.8 MB 10.7 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 84.1/159.8 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 84.6/159.8 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 85.2/159.8 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 85.7/159.8 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 86.3/159.8 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 86.7/159.8 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 87.3/159.8 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 87.8/159.8 MB 11.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 88.3/159.8 MB 11.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 88.9/159.8 MB 10.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 89.5/159.8 MB 11.3 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 90.0/159.8 MB 11.3 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 90.5/159.8 MB 11.5 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 91.1/159.8 MB 11.3 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 91.7/159.8 MB 11.5 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 92.2/159.8 MB 11.5 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 92.7/159.8 MB 11.5 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 93.3/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 93.8/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 94.3/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 94.9/159.8 MB 11.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.8/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 96.4/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 97.0/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 97.4/159.8 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 98.0/159.8 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 98.5/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 99.0/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 99.5/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 100.0/159.8 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 100.6/159.8 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 101.1/159.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 101.5/159.8 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 102.0/159.8 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 102.3/159.8 MB 11.3 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 102.7/159.8 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 103.1/159.8 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 103.7/159.8 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 104.2/159.8 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 104.7/159.8 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 105.3/159.8 MB 10.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.6/159.8 MB 10.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.6/159.8 MB 10.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.8 MB 10.1 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 107.2/159.8 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 107.7/159.8 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 107.8/159.8 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 108.6/159.8 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 109.0/159.8 MB 10.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 109.5/159.8 MB 10.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 109.9/159.8 MB 10.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 110.5/159.8 MB 10.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 111.1/159.8 MB 10.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 111.6/159.8 MB 10.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 112.2/159.8 MB 10.6 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 112.7/159.8 MB 10.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 113.3/159.8 MB 11.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 113.7/159.8 MB 11.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 114.2/159.8 MB 11.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 114.7/159.8 MB 11.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 115.3/159.8 MB 11.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 115.8/159.8 MB 11.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 116.3/159.8 MB 11.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 116.7/159.8 MB 11.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 117.2/159.8 MB 10.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 117.7/159.8 MB 10.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 118.2/159.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 118.7/159.8 MB 11.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 119.2/159.8 MB 11.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 119.7/159.8 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 120.2/159.8 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 120.8/159.8 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 121.3/159.8 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 121.8/159.8 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 122.3/159.8 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 122.8/159.8 MB 11.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 123.2/159.8 MB 11.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 123.8/159.8 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 124.3/159.8 MB 11.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 124.7/159.8 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 125.2/159.8 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 125.7/159.8 MB 10.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 126.1/159.8 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 126.6/159.8 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 127.2/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 127.6/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 128.2/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 128.6/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 129.1/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 129.6/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 130.2/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 130.7/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 131.2/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 131.8/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 131.9/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 132.6/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 133.1/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 133.7/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 134.2/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 134.7/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 135.1/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 135.6/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 136.1/159.8 MB 10.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 136.6/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 137.1/159.8 MB 10.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 137.6/159.8 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 138.1/159.8 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 138.6/159.8 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 139.1/159.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 139.4/159.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 139.8/159.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 140.4/159.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 141.0/159.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 141.5/159.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 141.9/159.8 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.4/159.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.9/159.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 143.3/159.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 143.4/159.8 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 144.1/159.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 144.6/159.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 145.1/159.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 145.5/159.8 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 145.9/159.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 146.2/159.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 146.7/159.8 MB 10.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 147.3/159.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 147.8/159.8 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 148.1/159.8 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 148.6/159.8 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 149.2/159.8 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 149.7/159.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 150.1/159.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 150.6/159.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 151.1/159.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 151.6/159.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 152.2/159.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 152.7/159.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 153.3/159.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 153.9/159.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.5/159.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.0/159.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.5/159.8 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  156.1/159.8 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  156.6/159.8 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.1/159.8 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.6/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  158.1/159.8 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  158.7/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.2/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 159.8/159.8 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.18.0-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.4/1.2 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.9/1.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.3.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.7/2.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.2/2.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "   ---------------------------------------- 0.0/228.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/228.5 MB 10.5 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 1.1/228.5 MB 11.8 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 1.5/228.5 MB 10.8 MB/s eta 0:00:21\n",
      "   ---------------------------------------- 2.0/228.5 MB 11.7 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 2.5/228.5 MB 11.5 MB/s eta 0:00:20\n",
      "    --------------------------------------- 3.1/228.5 MB 11.6 MB/s eta 0:00:20\n",
      "    --------------------------------------- 3.6/228.5 MB 11.6 MB/s eta 0:00:20\n",
      "    --------------------------------------- 4.2/228.5 MB 11.7 MB/s eta 0:00:20\n",
      "    --------------------------------------- 4.7/228.5 MB 11.6 MB/s eta 0:00:20\n",
      "    --------------------------------------- 5.3/228.5 MB 11.6 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 5.8/228.5 MB 11.5 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 6.3/228.5 MB 11.6 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 7.0/228.5 MB 11.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 7.5/228.5 MB 11.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 8.0/228.5 MB 11.6 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 8.5/228.5 MB 11.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 9.1/228.5 MB 11.9 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 9.5/228.5 MB 11.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 10.0/228.5 MB 11.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 10.6/228.5 MB 11.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 11.2/228.5 MB 11.7 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 11.8/228.5 MB 11.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 12.3/228.5 MB 11.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 12.8/228.5 MB 11.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 13.4/228.5 MB 11.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 14.0/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 14.5/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 15.1/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 15.7/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 16.2/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 16.7/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 17.2/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 17.8/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 18.3/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 18.9/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 19.4/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 20.0/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 20.5/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 20.9/228.5 MB 12.1 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 21.5/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 21.9/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 22.6/228.5 MB 11.9 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 23.0/228.5 MB 11.7 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 23.3/228.5 MB 11.5 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 23.8/228.5 MB 11.3 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 24.2/228.5 MB 11.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 24.7/228.5 MB 11.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 25.2/228.5 MB 11.3 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 25.8/228.5 MB 11.3 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 26.2/228.5 MB 11.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 26.7/228.5 MB 10.9 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 27.1/228.5 MB 10.9 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 27.5/228.5 MB 10.9 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 28.0/228.5 MB 10.7 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 28.3/228.5 MB 10.7 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 28.7/228.5 MB 10.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 29.1/228.5 MB 10.2 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 29.4/228.5 MB 10.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 30.0/228.5 MB 10.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 30.5/228.5 MB 10.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 31.0/228.5 MB 10.2 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 31.4/228.5 MB 10.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 32.1/228.5 MB 10.2 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 32.7/228.5 MB 10.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 33.2/228.5 MB 10.2 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 33.7/228.5 MB 10.4 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 34.3/228.5 MB 10.6 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 34.9/228.5 MB 10.7 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 35.4/228.5 MB 10.7 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 36.0/228.5 MB 10.7 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 36.5/228.5 MB 10.9 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 37.0/228.5 MB 10.9 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 37.6/228.5 MB 10.9 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 38.1/228.5 MB 11.1 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 38.6/228.5 MB 11.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 39.2/228.5 MB 11.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 39.7/228.5 MB 11.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 40.3/228.5 MB 11.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 40.8/228.5 MB 11.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 41.4/228.5 MB 11.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 41.8/228.5 MB 12.1 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 42.3/228.5 MB 11.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 42.8/228.5 MB 11.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 43.2/228.5 MB 11.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 43.7/228.5 MB 11.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 44.1/228.5 MB 11.3 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 44.5/228.5 MB 11.3 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 45.0/228.5 MB 11.3 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 45.6/228.5 MB 11.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 46.0/228.5 MB 11.3 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 46.5/228.5 MB 11.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 47.0/228.5 MB 11.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 47.6/228.5 MB 11.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 48.1/228.5 MB 11.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 48.6/228.5 MB 11.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 49.2/228.5 MB 11.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 49.6/228.5 MB 10.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 50.1/228.5 MB 10.7 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 50.6/228.5 MB 10.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 51.1/228.5 MB 10.9 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 51.6/228.5 MB 10.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 52.0/228.5 MB 10.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 52.5/228.5 MB 10.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 53.0/228.5 MB 10.7 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 53.5/228.5 MB 10.9 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 54.1/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 54.6/228.5 MB 10.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 55.0/228.5 MB 10.9 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 55.5/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 56.0/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 56.5/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 57.1/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 57.7/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 58.2/228.5 MB 11.3 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 58.7/228.5 MB 11.3 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 59.3/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 59.7/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 60.1/228.5 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 60.7/228.5 MB 10.9 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 61.2/228.5 MB 11.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 61.8/228.5 MB 11.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 62.2/228.5 MB 11.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 62.6/228.5 MB 11.3 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 63.1/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 63.6/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 64.0/228.5 MB 10.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 64.6/228.5 MB 10.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 65.1/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 65.5/228.5 MB 10.9 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 66.2/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 66.7/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 67.2/228.5 MB 11.3 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 67.7/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 68.2/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 68.6/228.5 MB 10.9 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 69.1/228.5 MB 10.9 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 69.7/228.5 MB 10.9 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 70.2/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 70.7/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 71.3/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 71.9/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 72.4/228.5 MB 11.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 73.0/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 73.5/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 73.9/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 74.5/228.5 MB 11.7 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 74.9/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 75.5/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 76.0/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 76.6/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 77.0/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 77.6/228.5 MB 11.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 78.1/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 78.6/228.5 MB 11.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 79.3/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 79.8/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 80.3/228.5 MB 11.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 80.9/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 81.4/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 81.9/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 82.5/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 83.1/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 83.7/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 84.2/228.5 MB 11.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 84.6/228.5 MB 11.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 85.0/228.5 MB 11.5 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 85.5/228.5 MB 11.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 86.1/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 86.7/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 87.2/228.5 MB 11.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 87.7/228.5 MB 11.7 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 88.2/228.5 MB 11.7 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 88.7/228.5 MB 11.7 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 89.2/228.5 MB 11.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 89.8/228.5 MB 11.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 90.4/228.5 MB 11.7 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 90.9/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 91.4/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 91.8/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 92.4/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 92.9/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 93.4/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 93.9/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 94.5/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 95.0/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 95.6/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 96.1/228.5 MB 11.7 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 96.6/228.5 MB 11.7 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 97.0/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 97.5/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 98.1/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 98.5/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 99.0/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 99.4/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 99.9/228.5 MB 11.1 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 100.5/228.5 MB 11.1 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 101.1/228.5 MB 11.1 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 101.5/228.5 MB 11.1 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 102.1/228.5 MB 11.5 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 102.6/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 103.1/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 103.6/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 104.1/228.5 MB 11.3 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 104.6/228.5 MB 11.1 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 105.0/228.5 MB 11.1 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 105.6/228.5 MB 10.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 106.0/228.5 MB 10.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 106.5/228.5 MB 11.1 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 107.0/228.5 MB 10.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 107.4/228.5 MB 10.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 107.9/228.5 MB 10.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 108.4/228.5 MB 10.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 108.9/228.5 MB 11.1 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 109.4/228.5 MB 11.1 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 110.0/228.5 MB 11.1 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 110.5/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 110.9/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 111.5/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 112.0/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 112.5/228.5 MB 10.7 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 112.9/228.5 MB 10.7 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 113.5/228.5 MB 10.7 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 114.0/228.5 MB 11.1 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 114.5/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 115.1/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 115.5/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 116.0/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 116.5/228.5 MB 11.1 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 116.9/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 117.4/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 118.0/228.5 MB 11.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 118.4/228.5 MB 10.9 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 119.0/228.5 MB 11.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 119.5/228.5 MB 11.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 119.9/228.5 MB 11.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 120.5/228.5 MB 11.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 121.0/228.5 MB 11.1 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 121.4/228.5 MB 10.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 121.9/228.5 MB 10.9 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 122.2/228.5 MB 10.7 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 122.8/228.5 MB 10.7 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 123.2/228.5 MB 10.7 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 123.7/228.5 MB 10.7 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 124.1/228.5 MB 10.6 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 124.7/228.5 MB 10.6 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 125.1/228.5 MB 10.6 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 125.5/228.5 MB 10.6 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 125.9/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 126.3/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 126.8/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 127.3/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 127.9/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 128.4/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 128.8/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 129.3/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 129.8/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 130.3/228.5 MB 10.2 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 130.6/228.5 MB 10.2 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 131.1/228.5 MB 10.1 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 131.6/228.5 MB 10.2 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 132.1/228.5 MB 10.2 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 132.7/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 133.1/228.5 MB 10.2 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 133.6/228.5 MB 10.2 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 134.1/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 134.6/228.5 MB 10.4 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 135.2/228.5 MB 10.6 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 135.8/228.5 MB 10.7 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 136.4/228.5 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 136.9/228.5 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 137.4/228.5 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 137.9/228.5 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 138.4/228.5 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 138.8/228.5 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 139.3/228.5 MB 11.1 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 139.7/228.5 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 140.2/228.5 MB 10.9 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 140.7/228.5 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 141.2/228.5 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 141.8/228.5 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 142.3/228.5 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 142.9/228.5 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 143.3/228.5 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 143.8/228.5 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 144.2/228.5 MB 11.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 144.7/228.5 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 145.1/228.5 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 145.5/228.5 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 146.1/228.5 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 146.6/228.5 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 147.2/228.5 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 147.7/228.5 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 148.2/228.5 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 148.8/228.5 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 149.3/228.5 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 149.9/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 150.4/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 151.0/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 151.5/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 152.0/228.5 MB 11.1 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 152.5/228.5 MB 11.1 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 153.0/228.5 MB 11.1 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 153.6/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 154.0/228.5 MB 11.1 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 154.6/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 155.1/228.5 MB 11.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 155.6/228.5 MB 11.7 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 156.0/228.5 MB 11.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 156.4/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 157.0/228.5 MB 11.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 157.4/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 158.0/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 158.4/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 159.0/228.5 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 159.6/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 160.1/228.5 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 160.6/228.5 MB 11.3 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 161.1/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 161.6/228.5 MB 11.1 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 162.1/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 162.7/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 163.1/228.5 MB 11.1 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 163.7/228.5 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 164.2/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 164.7/228.5 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 165.3/228.5 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 165.6/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 166.1/228.5 MB 10.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 166.5/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 167.1/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 167.6/228.5 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 168.0/228.5 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 168.6/228.5 MB 11.3 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 169.1/228.5 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 169.6/228.5 MB 10.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 169.8/228.5 MB 10.7 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 170.1/228.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 170.5/228.5 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 170.7/228.5 MB 10.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 171.1/228.5 MB 9.9 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 171.3/228.5 MB 9.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 171.7/228.5 MB 9.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 172.1/228.5 MB 9.6 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 172.5/228.5 MB 9.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 172.9/228.5 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 173.4/228.5 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 173.9/228.5 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 174.5/228.5 MB 9.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 174.8/228.5 MB 9.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 175.2/228.5 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 175.7/228.5 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 176.3/228.5 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 176.8/228.5 MB 9.5 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 177.2/228.5 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 177.7/228.5 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 178.1/228.5 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 178.6/228.5 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 179.0/228.5 MB 9.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 179.6/228.5 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 180.1/228.5 MB 9.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 180.7/228.5 MB 9.6 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 181.1/228.5 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 181.5/228.5 MB 10.1 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 182.0/228.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 182.5/228.5 MB 10.4 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 183.0/228.5 MB 10.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 183.6/228.5 MB 10.7 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 184.1/228.5 MB 10.7 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 184.6/228.5 MB 10.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 185.1/228.5 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 185.6/228.5 MB 10.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 186.1/228.5 MB 10.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 186.7/228.5 MB 10.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 187.3/228.5 MB 10.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 187.8/228.5 MB 11.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 188.2/228.5 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 188.7/228.5 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 189.3/228.5 MB 11.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 189.7/228.5 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 190.3/228.5 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 190.8/228.5 MB 11.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 191.2/228.5 MB 11.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 191.8/228.5 MB 11.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 192.3/228.5 MB 11.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 192.8/228.5 MB 11.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 193.4/228.5 MB 11.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 193.8/228.5 MB 11.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 194.2/228.5 MB 11.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 194.8/228.5 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 195.2/228.5 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 195.8/228.5 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 196.3/228.5 MB 11.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 196.8/228.5 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 197.3/228.5 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 197.9/228.5 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 198.4/228.5 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 198.9/228.5 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 199.5/228.5 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 200.1/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 200.6/228.5 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 201.1/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 201.6/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 202.1/228.5 MB 11.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 202.7/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 203.2/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 203.7/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 204.3/228.5 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 204.9/228.5 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 205.3/228.5 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 205.7/228.5 MB 11.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 206.2/228.5 MB 11.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 206.4/228.5 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 206.7/228.5 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 207.1/228.5 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 207.6/228.5 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 208.2/228.5 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 208.6/228.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 209.0/228.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 209.5/228.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 209.9/228.5 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 210.4/228.5 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 210.9/228.5 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 211.4/228.5 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 211.9/228.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 212.4/228.5 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 212.7/228.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 213.1/228.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 213.6/228.5 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 214.2/228.5 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 214.7/228.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 215.2/228.5 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 215.7/228.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 216.3/228.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 216.8/228.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 217.2/228.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 217.7/228.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 218.1/228.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 218.6/228.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 219.0/228.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 219.5/228.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 220.1/228.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 220.5/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 221.1/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 221.5/228.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 222.1/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 222.5/228.5 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  223.0/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  223.4/228.5 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  223.9/228.5 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  224.4/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  224.9/228.5 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  225.4/228.5 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  225.9/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  226.4/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  227.0/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  227.5/228.5 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.0/228.5 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 228.5/228.5 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/3.5 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.9/3.5 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.3/3.5 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.9/3.5 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.4/3.5 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.9/3.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.3/3.5 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.4 kB ? eta -:--:--\n",
      "   -------------------------------------- - 276.5/286.4 kB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 286.4/286.4 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.5/1.7 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/5.7 MB 13.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.0/5.7 MB 12.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.4/5.7 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.9/5.7 MB 10.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.5/5.7 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.0/5.7 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.4/5.7 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.8/5.7 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.4/5.7 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.8/5.7 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.2/5.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 10.5 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 419.8/536.2 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 536.2/536.2 kB 6.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, networkx, mkl, torch, torchvision, torchaudio\n",
      "Successfully installed intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 sympy-1.12 tbb-2021.12.0 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\program files\\python310\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\program files\\python310\\lib\\site-packages (from tokenizers) (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\program files\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\program files\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\program files\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\program files\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python310\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python310\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python310\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 리스트를 텍스트 파일로 저장\n",
    "with open(\"sentences.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for sentence in sentences:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 WordPiece 토크나이저 초기화\n",
    "# tokenizer = BertWordPieceTokenizer(clean_text=True, handle_chinese_chars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\bert-wordpiece-vocab.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저 훈련\n",
    "# tokenizer.train(\n",
    "#     files=\"sentences.txt\",\n",
    "#     vocab_size=30522,\n",
    "#     min_frequency=2,\n",
    "#     show_progress=True,\n",
    "#     special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n",
    "#     limit_alphabet=1000,\n",
    "#     wordpieces_prefix=\"##\"\n",
    "# )\n",
    "\n",
    "# # 훈련된 토크나이저 저장\n",
    "# tokenizer.save_model(\".\", \"bert-wordpiece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 0\n",
      "Tokens: ['[CLS]', '0', '[SEP]']\n",
      "Token IDs: [2, 8, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 1\n",
      "Tokens: ['[CLS]', '1', '[SEP]']\n",
      "Token IDs: [2, 9, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: n\n",
      "Tokens: ['[CLS]', 'n', '[SEP]']\n",
      "Token IDs: [2, 23, 3]\n",
      "\n",
      "Original: a\n",
      "Tokens: ['[CLS]', 'a', '[SEP]']\n",
      "Token IDs: [2, 18, 3]\n",
      "\n",
      "Original: n\n",
      "Tokens: ['[CLS]', 'n', '[SEP]']\n",
      "Token IDs: [2, 23, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: N\n",
      "Tokens: ['[CLS]', 'n', '[SEP]']\n",
      "Token IDs: [2, 23, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 신\n",
      "Tokens: ['[CLS]', '시', '##ᆫ', '[SEP]']\n",
      "Token IDs: [2, 174, 74, 3]\n",
      "\n",
      "Original: 차\n",
      "Tokens: ['[CLS]', 'ᄎ', '##ᅡ', '[SEP]']\n",
      "Token IDs: [2, 33, 67, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 기\n",
      "Tokens: ['[CLS]', '기', '[SEP]']\n",
      "Token IDs: [2, 129, 3]\n",
      "\n",
      "Original: 타\n",
      "Tokens: ['[CLS]', 'ᄐ', '##ᅡ', '[SEP]']\n",
      "Token IDs: [2, 34, 67, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 기\n",
      "Tokens: ['[CLS]', '기', '[SEP]']\n",
      "Token IDs: [2, 129, 3]\n",
      "\n",
      "Original: 명\n",
      "Tokens: ['[CLS]', 'ᄆ', '##ᅧᆼ', '[SEP]']\n",
      "Token IDs: [2, 28, 99, 3]\n",
      "\n",
      "Original: 피\n",
      "Tokens: ['[CLS]', 'ᄑ', '##ᅵ', '[SEP]']\n",
      "Token IDs: [2, 35, 76, 3]\n",
      "\n",
      "Original: 보\n",
      "Tokens: ['[CLS]', 'ᄇ', '##ᅩ', '[SEP]']\n",
      "Token IDs: [2, 29, 84, 3]\n",
      "\n",
      "Original: 험\n",
      "Tokens: ['[CLS]', 'ᄒ', '##ᅥ', '##ᆷ', '[SEP]']\n",
      "Token IDs: [2, 36, 75, 77, 3]\n",
      "\n",
      "Original: 자\n",
      "Tokens: ['[CLS]', '자', '[SEP]']\n",
      "Token IDs: [2, 221, 3]\n",
      "\n",
      "Original: 1\n",
      "Tokens: ['[CLS]', '1', '[SEP]']\n",
      "Token IDs: [2, 9, 3]\n",
      "\n",
      "Original: 인\n",
      "Tokens: ['[CLS]', '이', '##ᆫ', '[SEP]']\n",
      "Token IDs: [2, 229, 74, 3]\n",
      "\n",
      "Original: 한\n",
      "Tokens: ['[CLS]', 'ᄒ', '##ᅡᆫ', '[SEP]']\n",
      "Token IDs: [2, 36, 116, 3]\n",
      "\n",
      "Original: 정\n",
      "Tokens: ['[CLS]', 'ᄌ', '##ᅥ', '##ᆼ', '[SEP]']\n",
      "Token IDs: [2, 32, 75, 64, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 8\n",
      "Tokens: ['[CLS]', '8', '[SEP]']\n",
      "Token IDs: [2, 16, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 미\n",
      "Tokens: ['[CLS]', '미', '[SEP]']\n",
      "Token IDs: [2, 100, 3]\n",
      "\n",
      "Original: 가\n",
      "Tokens: ['[CLS]', '가', '[SEP]']\n",
      "Token IDs: [2, 165, 3]\n",
      "\n",
      "Original: 입\n",
      "Tokens: ['[CLS]', '이', '##ᆸ', '[SEP]']\n",
      "Token IDs: [2, 229, 88, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 미\n",
      "Tokens: ['[CLS]', '미', '[SEP]']\n",
      "Token IDs: [2, 100, 3]\n",
      "\n",
      "Original: 가\n",
      "Tokens: ['[CLS]', '가', '[SEP]']\n",
      "Token IDs: [2, 165, 3]\n",
      "\n",
      "Original: 입\n",
      "Tokens: ['[CLS]', '이', '##ᆸ', '[SEP]']\n",
      "Token IDs: [2, 229, 88, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 1\n",
      "Tokens: ['[CLS]', '1', '[SEP]']\n",
      "Token IDs: [2, 9, 3]\n",
      "\n",
      "Original: 5\n",
      "Tokens: ['[CLS]', '5', '[SEP]']\n",
      "Token IDs: [2, 13, 3]\n",
      "\n",
      "Original: 0\n",
      "Tokens: ['[CLS]', '0', '[SEP]']\n",
      "Token IDs: [2, 8, 3]\n",
      "\n",
      "Original: 0\n",
      "Tokens: ['[CLS]', '0', '[SEP]']\n",
      "Token IDs: [2, 8, 3]\n",
      "\n",
      "Original: 0\n",
      "Tokens: ['[CLS]', '0', '[SEP]']\n",
      "Token IDs: [2, 8, 3]\n",
      "\n",
      "Original: K\n",
      "Tokens: ['[CLS]', 'k', '[SEP]']\n",
      "Token IDs: [2, 22, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 1\n",
      "Tokens: ['[CLS]', '1', '[SEP]']\n",
      "Token IDs: [2, 9, 3]\n",
      "\n",
      "Original: /\n",
      "Tokens: ['[CLS]', '/', '[SEP]']\n",
      "Token IDs: [2, 7, 3]\n",
      "\n",
      "Original: 0\n",
      "Tokens: ['[CLS]', '0', '[SEP]']\n",
      "Token IDs: [2, 8, 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# # 저장된 토크나이저 모델 로드\n",
    "# tokenizer = BertWordPieceTokenizer(\"bert-wordpiece-vocab.txt\", lowercase=True)\n",
    "\n",
    "# # 테스트할 문장\n",
    "# test_sentences = df_yn[\"processed\"][1]\n",
    "\n",
    "# # 각 문장을 토큰화하고 결과 출력\n",
    "# for sentence in test_sentences:\n",
    "#     output = tokenizer.encode(sentence)\n",
    "#     print(f\"Original: {sentence}\")\n",
    "#     print(f\"Tokens: {output.tokens}\")\n",
    "#     print(f\"Token IDs: {output.ids}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3, 267777]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\삼성화재\\git_share\\hyper-personalized_car_accident_prediction\\Model\\BERT.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Split data into train and test sets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_inputs, test_inputs, train_labels, test_labels \u001b[39m=\u001b[39m train_test_split(inputs, labels, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m CustomDataset(train_inputs, train_labels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m CustomDataset(test_inputs, test_labels)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2657\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2657\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2660\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    515\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3, 267777]"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "train_dataset = CustomDataset(train_inputs, train_labels)\n",
    "test_dataset = CustomDataset(test_inputs, test_labels)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load BERT model for binary classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training the model\n",
    "model.train()\n",
    "for epoch in range(3):  # Train for 3 epochs\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22184\\2598980054.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\삼성화재\\git_share\\hyper-personalized_car_accident_prediction\\Model\\BERT.ipynb Cell 24\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X32sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X32sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m labels \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X32sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, labels\u001b[39m=\u001b[39;49mlabels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X32sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/%EC%82%BC%EC%84%B1%ED%99%94%EC%9E%AC/git_share/hyper-personalized_car_accident_prediction/Model/BERT.ipynb#X32sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1539\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1533\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1539\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1540\u001b[0m     input_ids,\n\u001b[0;32m   1541\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1542\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1543\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1544\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1545\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1546\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1547\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1548\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1549\u001b[0m )\n\u001b[0;32m   1551\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1553\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    979\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    981\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    982\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    983\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    986\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    987\u001b[0m )\n\u001b[1;32m--> 988\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    989\u001b[0m     embedding_output,\n\u001b[0;32m    990\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    991\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    992\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    993\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    994\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    995\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    996\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    997\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    998\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    999\u001b[0m )\n\u001b[0;32m   1000\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    571\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    572\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    573\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         output_attentions,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 582\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    583\u001b[0m         hidden_states,\n\u001b[0;32m    584\u001b[0m         attention_mask,\n\u001b[0;32m    585\u001b[0m         layer_head_mask,\n\u001b[0;32m    586\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    587\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    588\u001b[0m         past_key_value,\n\u001b[0;32m    589\u001b[0m         output_attentions,\n\u001b[0;32m    590\u001b[0m     )\n\u001b[0;32m    592\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    511\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    512\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 514\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    515\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    516\u001b[0m )\n\u001b[0;32m    517\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    519\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    526\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 527\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    528\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 439\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    440\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    441\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load the dataset\n",
    "df_yn = pd.read_csv(\"C:/Users/USER/삼성화재/git_share/hyper-personalized_car_accident_prediction/Dataset/고객별 사고 유무 기본 데이터.csv\", encoding=\"UTF-8\", engine='python')\n",
    "\n",
    "# Function to preprocess the data\n",
    "def remove_decimal_and_convert_to_str(value):\n",
    "    if pd.isnull(value):\n",
    "        return 'nan'\n",
    "    if isinstance(value, float):\n",
    "        value = int(value) if value.is_integer() else value\n",
    "    return str(value)\n",
    "\n",
    "# Apply preprocessing\n",
    "df_yn['processed'] = df_yn.apply(lambda row: '/'.join(row.apply(remove_decimal_and_convert_to_str)), axis=1)\n",
    "\n",
    "# Extract sentences and labels\n",
    "sentences = df_yn['processed'].tolist()\n",
    "labels = [int(sentence.split('/')[-1]) for sentence in sentences]\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the sentences\n",
    "train_encodings = tokenizer(train_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(test_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Create a Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load BERT model for binary classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training the model\n",
    "model.train()\n",
    "for epoch in range(3):  # Train for 3 epochs\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
